{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATADIR = \"./../image_data\"\n",
    "EEG_dir = \"./../ImageNet-EEG\"\n",
    "\n",
    "CATEGORIES = [\"animal\", \"blue_sky\", \"device\",\"flying_object\", \"green_color\", \"musical_instrument\",\"plant\", \"red_color\", \"vehicle\",\"water\", ]\n",
    "subjects_EEG = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"] \n",
    "\n",
    "training_data = []\n",
    "test_data = []\n",
    "\n",
    "\n",
    "\n",
    "for category in CATEGORIES:  # do blue_sky and green_color\n",
    "    path = os.path.join(DATADIR,category)  # create blue_sky and green_color\n",
    "    class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=blue_sky 1=green_color\n",
    "    img_counter = 0\n",
    "    \n",
    "    for img in os.listdir(path):  # iterate over each image blue_sky and green_color\n",
    "        # print(img)\n",
    "        img_counter +=1\n",
    "        for subject in subjects_EEG: # do 1 ,2, 3, 4, 5, 6\n",
    "            path_EEG = os.path.join(EEG_dir,subject)\n",
    "            \n",
    "            for eeg in os.listdir(path_EEG):\n",
    "                if img == eeg.strip('.eeg.mat'):\n",
    "                    if img_counter  < (np.array(os.listdir(path)).size*80/100): # 80 % training \n",
    "                        EEGs= sio.loadmat(os.path.join(path_EEG,eeg), matlab_compatible=True)\n",
    "                        eeg_array = EEGs['x']\n",
    "                        new_array = eeg_array[319:479,:]\n",
    "                        training_data.append([new_array, class_num])  # add this to our training_date\n",
    "                        # print(\"train\"+eeg)\n",
    "                    else:\n",
    "                        EEGs= sio.loadmat(os.path.join(path_EEG,eeg), matlab_compatible=True)\n",
    "                        eeg_array = EEGs['x']\n",
    "                        new_array = eeg_array[319:479,:]\n",
    "                        test_data.append([new_array, class_num])  # add this to our training_date\n",
    "                        # print(\"test\"+eeg)\n",
    "\n",
    "                            \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in test_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for features,label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for features,label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(-1, 160, 128)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test).reshape(-1, 160, 128)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "map_dict = dict() # dictionary to hold the target position of a channel in the target 2d map\n",
    "# read csv file as a list of lists\n",
    "with open('map_v2.csv', 'r',encoding='utf-8') as csv_file:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(csv_file)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    m = list(csv_reader)\n",
    "    print(m)\n",
    "    for i,row in enumerate(m):\n",
    "        for j,c in enumerate(row):\n",
    "            # if the cell is not empty\n",
    "            if c:\n",
    "                c = c.replace(u'\\ufeff','').strip() # handle encoding issue, to be enhanced\n",
    "                assert(c not in map_dict)\n",
    "                map_dict[c] = (i,j) # to be checked as it depends on the orientation\n",
    "assert(len(map_dict)==128)\n",
    "print(map_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict['FFT9h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file as a list of lists\n",
    "with open('key.csv', 'r',encoding='utf-8') as csv_file:\n",
    "    # pass the file object to reader() to get the reader object\n",
    "    csv_reader = reader(csv_file)\n",
    "    # Pass reader object to list() to get a list of lists\n",
    "    key = list(csv_reader)\n",
    "    key =[item for sublist in key for item in sublist] # flatten the key\n",
    "    assert(len(key)==128)\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if all channels are mapped\n",
    "for k in key:\n",
    "    if k not in map_dict:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_map(vector):\n",
    "    #print(vector.shape)\n",
    "    #print(vector)\n",
    "    assert(vector.shape==(128,))\n",
    "    m = np.zeros((14,11))\n",
    "    for idx, value in np.ndenumerate(vector):\n",
    "        assert(key[idx[0]] in map_dict) # np return index as tuple \n",
    "        x,y = map_dict[key[idx[0]]]\n",
    "        m[x,y] = value\n",
    "        #print(m[x,y])\n",
    "    assert(np.count_nonzero(m)==128)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = np.zeros((X_train.shape[0],X_train.shape[1], 14, 11))\n",
    "X_test_encoded = np.zeros((X_test.shape[0],X_test.shape[1], 14, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_to_map(X_train[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can this code be enhanced? \n",
    "for i in range(X_train.shape[0]):\n",
    "    for j in range(X_train.shape[1]):\n",
    "        X_train_encoded[i,j] = vector_to_map(X_train[i,j])\n",
    "        \n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(X_test.shape[1]):\n",
    "        X_test_encoded[i,j] = vector_to_map(X_test[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train_encoded.shape)\n",
    "print( X_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X_train_encoded_full_2D.pickle\",\"wb\")\n",
    "pickle.dump(X_train_encoded, pickle_out,  protocol=4)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train_full.pickle\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# We can always load it in to our current script, or a totally new one by doing:\n",
    "\n",
    "''' \n",
    "pickle_in = open(\"X_train.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "'''\n",
    "\n",
    "pickle_out = open(\"X_test_encoded_full_2D.pickle\",\"wb\")\n",
    "pickle.dump(X_test_encoded, pickle_out, protocol=4)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_test_full.pickle\",\"wb\")\n",
    "pickle.dump(y_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded[1,1,5:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
