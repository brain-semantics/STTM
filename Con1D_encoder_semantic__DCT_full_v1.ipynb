{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no lstm # come from v3\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Conv1D, Activation, MaxPooling1D, Flatten, Attention, Input\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "pickle_in = open(\"X_train_full.pickle\",\"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_train_full.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "\n",
    "pickle_in = open(\"X_test_full.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_test_full.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n",
    "# layer = tf.keras.layers.LayerNormalization(axis=[2])\n",
    "# output = layer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "sample = X_train.shape[0]\n",
    "rows = X_train.shape[1]\n",
    "columns = X_train.shape[2]\n",
    "for i in range(0, sample):\n",
    "    for x in range(0,rows):\n",
    "        for y in range(0,columns):\n",
    "            if(X_train[i][x][y] in {'NaN','infinity','nan','Infinity'}):\n",
    "                count+=1\n",
    "                print(\"Deleted Rows: \"+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized Data\n",
    "'''\n",
    "X_train_normalized = ((X_train-np.min(X_train))/(np.max(X_train)-np.min(X_train)))\n",
    "X_test_normalized = ((X_test-np.min(X_test))/(np.max(X_test)-np.min(X_test)))\n",
    "\n",
    "\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(X_train)\n",
    "X_train_normalized = layer(X_train)\n",
    "\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(X_test)\n",
    "X_test_normalized = layer(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = tf.signal.dct(X_train, type=2, n=None, axis=-1, norm=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, Flatten, Activation, RepeatVector, Permute, Multiply, Lambda, Concatenate\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "# input layer\n",
    "EEG = Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "# first feature extractor\n",
    "\n",
    "norm1 = tf.keras.layers.LayerNormalization(axis=2)(EEG)\n",
    "\n",
    "conv1 = Conv1D(64, (3), input_shape=(X_train.shape[1:]))(norm1)\n",
    "relu1 = Activation('relu')(conv1)\n",
    "\n",
    "conv2 = Conv1D(64, (2))(relu1)\n",
    "relu2 = Activation('relu')(conv2)\n",
    "pool1 = MaxPooling1D(pool_size=(2))(relu2)\n",
    "\n",
    "conv3 = Conv1D(64, (2))(pool1)\n",
    "relu3 = Activation('relu')(conv2)\n",
    "pool2 = MaxPooling1D(pool_size=(2))(relu3)\n",
    "\n",
    "flat1 = Flatten()(pool2)\n",
    "\n",
    "# second feature extractor\n",
    "DCT1 = tf.signal.dct(EEG, type=2, n=None, axis=-1, norm=None, name=None)\n",
    "norm2= tf.keras.layers.LayerNormalization(axis=2)(DCT1)\n",
    "#activations = LSTM(128, input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True)(norm2)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = Dense(1, activation='tanh')(norm2)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(128)(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "\n",
    "sent_representation = Multiply()([norm2, attention])\n",
    "sent_representation = Lambda(lambda xin: K.sum(xin, axis=1))(sent_representation)\n",
    "\n",
    "flat2 = Flatten()(sent_representation)\n",
    "\n",
    "# merge feature extractors\n",
    "merge = Concatenate()([flat1, flat2])\n",
    "\n",
    "dence1 = Dense(512)(merge)\n",
    "\n",
    "dence2= Dense(8)(dence1)\n",
    "softmax1 = Activation('softmax')(dence2)\n",
    "model = keras.Model(inputs=EEG, outputs=softmax1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 8)\n",
    "y_test = keras.utils.to_categorical(y_test, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "NAME = \"conv1D_DCT_full_v1\"\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"conv1D_DCT_full_v1.weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train,\n",
    "          np.array(y_train),\n",
    "          epochs=20,\n",
    "          validation_data=(X_test, np.array(y_test)),\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([X_test[0].reshape(-1,440,128)])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('conv1D_46_46_64_512_2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"blue_sky\", \"green_color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"conv1D_46_46_64_512_2.model\")\n",
    "\n",
    "prediction = model.predict([X_test[0].reshape(-1,440,128)])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
